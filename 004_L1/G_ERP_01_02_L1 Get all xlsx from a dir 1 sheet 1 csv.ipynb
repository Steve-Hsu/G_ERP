{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01_02_Walk through and turn all BOM(xlsx) to trimed csv in a directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd pty modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openpyxl import load_workbook\n",
    "from os import walk\n",
    "from os.path import join\n",
    "\n",
    "# Custom modules\n",
    "from G_ERP_01_01_L1_Get_xlsx_1_sheet_1_csv import get_xlsx, trim_None_col, trim_None_row\n",
    "\n",
    "# DataSource \n",
    "DataDir = 'Original_BOM_L1'\n",
    "SaveDir = 'result_1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function_1\n",
    "### sheet_num()\n",
    "* Check number of how many sheet in the xlsm are we want\n",
    "* Based on the number of the wanted sheet ,computer will produce as many csv from 1 xlsx file as the nubmer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sheet_num(filepath, wanted = ['bom', 'trims', 'shell', 'fabric', 'accessories']):\n",
    "    wb = load_workbook(filepath)\n",
    "    name_list = []\n",
    "    \n",
    "    for sheet_name in wb.sheetnames:\n",
    "        name = str(sheet_name).lower() \n",
    "        if any( x in name for x in wanted):\n",
    "            name_list.append(sheet_name)\n",
    "            \n",
    "    return name_list\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function_2\n",
    "### csvs_convert()\n",
    "* In a directory, convert all the xlsx file into csv file.\n",
    "* Meanwhile, convert all the string into lowercase.\n",
    "* With the func, sheet_num(), it's enable of converting numbers of wated sheet in each xlsx file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csvs_convert(from_dir_path, to_dir_path):\n",
    "    converted_xlsm_num = 0\n",
    "    converted_xlsm = []\n",
    "    converted_csv = 0\n",
    "    for root, dirnames, filenames in walk(from_dir_path):\n",
    "        \n",
    "        # walk through each xlsx file\n",
    "        for file_name in filenames:\n",
    "            \n",
    "            # get the path of the file\n",
    "            # Appoint the method only work with .xlsx file.\n",
    "            if file_name.endswith('.xlsx') :\n",
    "                filepath = join(root, file_name)\n",
    "                converted_xlsm_num = converted_xlsm_num + 1\n",
    "                converted_xlsm.append(file_name)\n",
    "                print(file_name)\n",
    "                # How many sheet we want how many csv will be created\n",
    "                for sheet in sheet_num(filepath):\n",
    "                    # Report how many sheet is processed.\n",
    "                    converted_csv = converted_csv + 1\n",
    "                    \n",
    "                    # custom method 1\n",
    "                    bom = get_xlsx(filepath, sheet)\n",
    "                    \n",
    "                    # custom method 2\n",
    "                    trim_col_bom = trim_None_col(bom)\n",
    "                    \n",
    "                    # custom method 3\n",
    "                    trim_row_bom = trim_None_row(trim_col_bom)\n",
    "                    \n",
    "                    # convert all string to lowercase\n",
    "                    trim_row_bom = trim_row_bom.apply(lambda x: x.astype(str).str.lower())\n",
    "                    \n",
    "                    # Change the string variabe, the file_name, replace the .xlsx by .csv\n",
    "                    csv_file_name = file_name.replace('.xlsx', '')\n",
    "                    \n",
    "                    # Save the result as csv with the string variable, the file_name.\n",
    "                    trim_row_bom.to_csv(join(to_dir_path, csv_file_name + '_' + sheet+ '.csv')) \n",
    "                   \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1-107-17_BARSTOW.xlsx\n",
      "L1-210-17_THUNDER_PANT.xlsx\n",
      "L1TA_201_17_LORETTA_TWILL_OVERALL.xlsx\n",
      "L1TA-203-17_SIREN_PANT.xlsx\n",
      "L1TA-107-18_NIGHTINGALE_04_04_17.xlsx\n",
      "L1-111-17_FLINT.xlsx\n",
      "L1-203-18_AMERICANA_03-30-17.xlsx\n",
      "L1TA_202_17_LORETTA_DENIM_OVERALL.xlsx\n",
      "L1TA-204-18_HEARTBREAKER_TWILL_04_05_17.xlsx\n",
      "L1TA-106-18_LALENA_04_04_17.xlsx\n",
      "L1-209-17_SKINNY_DENIM_PANT.xlsx\n",
      "L1-105-18_AFTERSHOCK_4-07-17.xlsx\n",
      "L1TA_205_17_HEARTBREAKER_TWILL_PANT.xlsx\n",
      "L1-113-18_KENSINGTON_4-06-17.xlsx\n",
      "L1-102-17_WINDSOR.xlsx\n",
      "L1-210-18_THUNDER_03-30-17.xlsx\n",
      "L1-206-18_TAXWOOD_PANT_04_10_17.xlsx\n",
      "L1-205-18_SLIM_CHINO_04-04-17.xlsx\n",
      "L1-209-18_SLIM_CARGO_04-04-17.xlsx\n",
      "L1TA-101-18_EMMA_04-05-17.xlsx\n",
      "L1-102-18_SUTTON_4_7_17.xlsx\n",
      "L1-105-17_LAWTON.xlsx\n",
      "L1TA-103-18_FAIRBANKS_04_12_17.xlsx\n",
      "L1-206-17_STRAIGHT_LEG_CHINO_PANT.xlsx\n",
      "L1-207-17_SLIM_BASIC_PANT.xlsx\n",
      "L1-201-17_GEMINI_2L_PANT.xlsx\n",
      "L1TA-102-18_TAMARYN_04-04-17.xlsx\n",
      "L1-211-18_AFTERSHOCK_PANT_04-10-17.xlsx\n",
      "L1TA-203-18-B_SIREN_04_05_17.xlsx\n",
      "L1-108-17_ROCKEFELLER.xlsx\n",
      "L1TA-205-18_HELLDIVER_04_05_17.xlsx\n",
      "L1TA-203-18-A_SIREN_04_05_17.xlsx\n",
      "L1-106-18_HASTING_4-12-17.xlsx\n",
      "L1-106-17_HASTING_07_28_16.xlsx\n",
      "L1-108-18_TAXWOOD_JACKET_4-7-17.xlsx\n",
      "L1-103-18_GRIMEY_4-03-17.xlsx\n",
      "L1-202-17_OVERALL.xlsx\n",
      "L1TA-104-18_ANWEN_04-12-17.xlsx\n",
      "L1-101-18_ALPHA_4-7-17.xlsx\n",
      "L1-211-17_THE_ONE_PANT_BONDED_3L.xlsx\n",
      "L1-111-18_STOOGE_4-06-17.xlsx\n",
      "L1TA-105-18_PROWLER_04-04-17.xlsx\n",
      "L1TA-108-18_STRANGELOVE FLANNEL_32917.xlsx\n",
      "L1-208-18_SKINNY_TWILL_04-04-17.xlsx\n",
      "L1-101-17_ALPHA.xlsx\n",
      "L1-103-17_BREWIN.xlsx\n",
      "L1-109-18_ROCKEFELLER_4-07-17.xlsx\n",
      "L1-104-16_LEGACY_JAN4.xlsx\n",
      "L1-109-17_STOOGE_072616.xlsx\n",
      "L1-208-17_SKINNY_TWILL_PANT.xlsx\n",
      "L1-104-18_LEGACY_4-07-17.xlsx\n",
      "L1-204-17_REGULAR_FIT_CARGO_PANT.xlsx\n",
      "L1-203-17_AMERICANA.xlsx\n",
      "L1-207-18_STRAIGHT_STANDARD_04-04-17.xlsx\n",
      "L1-201-18_GEMINI_04-05-17.xlsx\n",
      "L1TA-201-18_LORETTA_OVERALL_04_05_17.xlsx\n",
      "L1-107-18_WILCOX_4-7-17.xlsx\n",
      "L1-202-18_OVERALL_04_05_17.xlsx\n",
      "L1TA-107-17_MOONAGE_090916.xlsx\n",
      "L1TA_204_17_HEARTBREAKER_DENIM_PANT.xlsx\n",
      "L1-205-17_SLIM_CHINO_PANT.xlsx\n",
      "L1-107-17_BARSTOW_MARCH17.xlsx\n",
      "L1-104-17_LEGACY_MARCH17.xlsx\n",
      "CPU times: user 6min 7s, sys: 4.13 s, total: 6min 11s\n",
      "Wall time: 6min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x = csvs_convert(DataDir, SaveDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
