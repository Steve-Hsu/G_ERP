{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column_Classify\n",
    "## Goal of the function\n",
    "### This func is basically an adapted copy of func \"Category_Classify\", that from last step.\n",
    "## Basic workflow\n",
    "* The dataSource of the func is Categoried_M_List\n",
    "* Classify each column in the Categoried_M_List, and fill the fitile for each column with string such as \"Item\", \"Description\", \"Position\" etc.\n",
    "* Save the result as a Col_classified_M_List\n",
    "\n",
    "## Problems\n",
    "* 2020/04/02 : Stucked in the \"Core Function\". \n",
    "* The fucn can classify in the direction of column, but when the COL_LIST added to much or other key word like \"insulation\", error will occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3610,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# File system\n",
    "from os import walk\n",
    "from os.path import join\n",
    "\n",
    "# Switch area\n",
    "COL_LIST =['label', 'insulation', 'interfacing', 'zipper', 'fabric']\n",
    "# COL_LIST =['item', 'description', 'spec', 'position', 'color_way', 'insulation']\n",
    "# COL_LIST =['fabric']\n",
    "# COL_LIST =['colorway']\n",
    "\n",
    "VOCAB_SIZE = 900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3611,
   "metadata": {},
   "outputs": [],
   "source": [
    "FROM_DIR = 'DataSource/Categoried_M-List'\n",
    "TO_DIR = 'result'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3612,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test \n",
    "DATA = FROM_DIR + '/AB18MJ1_032_ BOM_032 BOM_CATE_classified_M-List.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "* We need to convert the M-List(Type in DF)through several process to Full matrix, so we can classify the M-List with the trained_data we made before.\n",
    "## Process\n",
    "### delete_col()\n",
    "### turn_series()\n",
    "### stemmered_nltk_convert()\n",
    "### make_sparse_matrix()\n",
    "### make_full_feature()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## delete_col()\n",
    "* Delete the none columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3613,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_col(m_list):\n",
    "    for col in m_list:\n",
    "        if m_list[col].count() == 0:\n",
    "            m_list = m_list.drop(col, axis = 1)\n",
    "    return m_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3614,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "bom = pd.read_csv(DATA, index_col = None, encoding = 'ISO-8859-1')\n",
    "M_List = delete_col(bom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## turn_series()\n",
    "#### Walk through bom\n",
    "* Parse a xlsm of bom, turn the columns into cells, all the cells will form a col.\n",
    "* Put the cell to the classify function\n",
    "* Return the index of column that is True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3615,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_series(bom):\n",
    "    '''\n",
    "    \n",
    "    The parameter of the func is a dataFrame\n",
    "    \n",
    "    '''\n",
    "    database = []\n",
    "    \n",
    "    for col in bom:\n",
    "        col_str = str()\n",
    "        for row in bom.index:\n",
    "            col_str = col_str + ', ' + str(bom.at[row, col])\n",
    "        database.append(col_str)\n",
    "    \n",
    "    col = pd.Series(database)\n",
    "#     index_list = classify_series(col)\n",
    "    \n",
    "    return col#### Below is the original function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below is the original function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def turn_series(bom):\n",
    "    '''\n",
    "    \n",
    "    The parameter of the func is a dataFrame\n",
    "    \n",
    "    '''\n",
    "    database = []\n",
    "    \n",
    "    for row in bom.index:\n",
    "        row_str = str()\n",
    "        for col in bom:\n",
    "            row_str = row_str + ', ' + str(bom.at[row, col])\n",
    "        database.append(row_str)\n",
    "    \n",
    "    col = pd.Series(database)\n",
    "*     index_list = classify_series(col)\n",
    "    \n",
    "    return col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stemmered_nltk_convert() \n",
    "* Nltk stemmered Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3616,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmered_nltk_convert(col_of_df):\n",
    "    '''\n",
    "    Parameter of this function is a column of a dataFrame.\n",
    "    \n",
    "    '''\n",
    "    # difine Stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # Difine Stemmer\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    \n",
    "    # converts to lower case and splits up the words\n",
    "    words = word_tokenize(col_of_df)\n",
    "    filtered_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        # Removes the stop words and punctuation\n",
    "        # if word is not in the stop_words list and is not a alpha.\n",
    "        if word not in stop_words and word.isalpha():\n",
    "            filtered_words.append(stemmer.stem(word))\n",
    "            \n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3617,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "new_List = turn_series(M_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3618,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     , 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13...\n",
       "1     , 3, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 2...\n",
       "2     , insulation, fabric, fabric, fabric, fabric, ...\n",
       "3     , nan, nan, A, B, C, D, E, F, G, H, I, J, K, L...\n",
       "4     , nan, nan, Shell Fabric, Shell Fabric, Shell ...\n",
       "5     , Insulation:, nan, SOTD109-C1-Y 100% Polyeste...\n",
       "6     , 100gm in the body hood sleeves, nan, Main bo...\n",
       "7     , nan, FABRICS & LININGS, nan, nan, nan, nan, ...\n",
       "8     , Collection: Freedom, nan, VINTAGE BLACK, nan...\n",
       "9     , nan, nan, nan, DINOFLAGE, BLACK, BLACK, BLAC...\n",
       "10    , nan, nan, BLACK, nan, OXBLOOD, BLACK, BLACK,...\n",
       "11    , nan, nan, DARK NAVY, nan, CAMEL, BLACK, BLAC...\n",
       "12    , nan, nan, AB18MJ1_032, AB18MJ1_032, AB18MJ1_...\n",
       "dtype: object"
      ]
     },
     "execution_count": 3618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "new_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3619,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "stemmed_List = new_List.apply(stemmered_nltk_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3620,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                    []\n",
       "1                                                    []\n",
       "2     [insul, fabric, fabric, fabric, fabric, fabric...\n",
       "3     [nan, nan, a, b, c, d, e, f, g, h, i, j, k, l,...\n",
       "4     [nan, nan, shell, fabric, shell, fabric, shell...\n",
       "5     [insul, nan, polyest, suppli, soli, polyest, s...\n",
       "6     [bodi, hood, sleev, nan, main, bodi, main, bod...\n",
       "7     [nan, fabric, line, nan, nan, nan, nan, nan, n...\n",
       "8     [collect, freedom, nan, vintag, black, nan, bl...\n",
       "9     [nan, nan, nan, dinoflag, black, black, black,...\n",
       "10    [nan, nan, black, nan, oxblood, black, black, ...\n",
       "11    [nan, nan, dark, navi, nan, camel, black, blac...\n",
       "12                                 [nan, nan, nan, nan]\n",
       "dtype: object"
      ]
     },
     "execution_count": 3620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3621,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>insul</td>\n",
       "      <td>fabric</td>\n",
       "      <td>fabric</td>\n",
       "      <td>fabric</td>\n",
       "      <td>fabric</td>\n",
       "      <td>fabric</td>\n",
       "      <td>fabric</td>\n",
       "      <td>fabric</td>\n",
       "      <td>fabric</td>\n",
       "      <td>insul</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>e</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>h</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>shell</td>\n",
       "      <td>fabric</td>\n",
       "      <td>shell</td>\n",
       "      <td>fabric</td>\n",
       "      <td>shell</td>\n",
       "      <td>fabric</td>\n",
       "      <td>line</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>insul</td>\n",
       "      <td>nan</td>\n",
       "      <td>polyest</td>\n",
       "      <td>suppli</td>\n",
       "      <td>soli</td>\n",
       "      <td>polyest</td>\n",
       "      <td>suppli</td>\n",
       "      <td>soli</td>\n",
       "      <td>polyest</td>\n",
       "      <td>suppli</td>\n",
       "      <td>...</td>\n",
       "      <td>pocket</td>\n",
       "      <td>zipper</td>\n",
       "      <td>close</td>\n",
       "      <td>vent</td>\n",
       "      <td>zip</td>\n",
       "      <td>close</td>\n",
       "      <td>down</td>\n",
       "      <td>elast</td>\n",
       "      <td>web</td>\n",
       "      <td>taffeta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>bodi</td>\n",
       "      <td>hood</td>\n",
       "      <td>sleev</td>\n",
       "      <td>nan</td>\n",
       "      <td>main</td>\n",
       "      <td>bodi</td>\n",
       "      <td>main</td>\n",
       "      <td>bodi</td>\n",
       "      <td>sleev</td>\n",
       "      <td>hood</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>nan</td>\n",
       "      <td>fabric</td>\n",
       "      <td>line</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>collect</td>\n",
       "      <td>freedom</td>\n",
       "      <td>nan</td>\n",
       "      <td>vintag</td>\n",
       "      <td>black</td>\n",
       "      <td>nan</td>\n",
       "      <td>black</td>\n",
       "      <td>black</td>\n",
       "      <td>black</td>\n",
       "      <td>black</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>dinoflag</td>\n",
       "      <td>black</td>\n",
       "      <td>black</td>\n",
       "      <td>black</td>\n",
       "      <td>black</td>\n",
       "      <td>black</td>\n",
       "      <td>black</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>black</td>\n",
       "      <td>nan</td>\n",
       "      <td>oxblood</td>\n",
       "      <td>black</td>\n",
       "      <td>black</td>\n",
       "      <td>black</td>\n",
       "      <td>black</td>\n",
       "      <td>black</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>dark</td>\n",
       "      <td>navi</td>\n",
       "      <td>nan</td>\n",
       "      <td>camel</td>\n",
       "      <td>black</td>\n",
       "      <td>black</td>\n",
       "      <td>black</td>\n",
       "      <td>black</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows × 192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0        1        2         3        4        5       6       7    \\\n",
       "0      None     None     None      None     None     None    None    None   \n",
       "1      None     None     None      None     None     None    None    None   \n",
       "2     insul   fabric   fabric    fabric   fabric   fabric  fabric  fabric   \n",
       "3       nan      nan        a         b        c        d       e       f   \n",
       "4       nan      nan    shell    fabric    shell   fabric   shell  fabric   \n",
       "5     insul      nan  polyest    suppli     soli  polyest  suppli    soli   \n",
       "6      bodi     hood    sleev       nan     main     bodi    main    bodi   \n",
       "7       nan   fabric     line       nan      nan      nan     nan     nan   \n",
       "8   collect  freedom      nan    vintag    black      nan   black   black   \n",
       "9       nan      nan      nan  dinoflag    black    black   black   black   \n",
       "10      nan      nan    black       nan  oxblood    black   black   black   \n",
       "11      nan      nan     dark      navi      nan    camel   black   black   \n",
       "12      nan      nan      nan       nan     None     None    None    None   \n",
       "\n",
       "        8       9    ...     182     183    184   185   186    187   188  \\\n",
       "0      None    None  ...    None    None   None  None  None   None  None   \n",
       "1      None    None  ...    None    None   None  None  None   None  None   \n",
       "2    fabric   insul  ...    None    None   None  None  None   None  None   \n",
       "3         g       h  ...    None    None   None  None  None   None  None   \n",
       "4      line   other  ...    None    None   None  None  None   None  None   \n",
       "5   polyest  suppli  ...  pocket  zipper  close  vent   zip  close  down   \n",
       "6     sleev    hood  ...    None    None   None  None  None   None  None   \n",
       "7       nan     nan  ...    None    None   None  None  None   None  None   \n",
       "8     black   black  ...    None    None   None  None  None   None  None   \n",
       "9     black   black  ...    None    None   None  None  None   None  None   \n",
       "10    black   black  ...    None    None   None  None  None   None  None   \n",
       "11    black   black  ...    None    None   None  None  None   None  None   \n",
       "12     None    None  ...    None    None   None  None  None   None  None   \n",
       "\n",
       "      189   190      191  \n",
       "0    None  None     None  \n",
       "1    None  None     None  \n",
       "2    None  None     None  \n",
       "3    None  None     None  \n",
       "4    None  None     None  \n",
       "5   elast   web  taffeta  \n",
       "6    None  None     None  \n",
       "7    None  None     None  \n",
       "8    None  None     None  \n",
       "9    None  None     None  \n",
       "10   None  None     None  \n",
       "11   None  None     None  \n",
       "12   None  None     None  \n",
       "\n",
       "[13 rows x 192 columns]"
      ]
     },
     "execution_count": 3621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_col_df = pd.DataFrame.from_records(stemmed_List.tolist())\n",
    "word_col_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make_sparse_matrix()\n",
    "### Sparse Matrix Function\n",
    "* Create a sparse Matrix for the data we want to predict\n",
    "* The difference of this function in comparition with Classification Model for Train data, is this function don't need CATEGORY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3622,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sparse_matrix(df, vocabulary):\n",
    "    \"\"\"\n",
    "    Param1:\n",
    "    The data we want to sparse, which must be in format of DataFrame.\n",
    "    \n",
    "    Param2:\n",
    "    The vocabulary, it is generated when we training datas.\n",
    "    \n",
    "    Returns a sparse matrix as dataframe\n",
    "    \"\"\"\n",
    " \n",
    "    indexed_words = pd.Index(vocabulary.VOCAB_WORD)\n",
    "    nr_rows = df.shape[0]\n",
    "    nr_cols = df.shape[1]\n",
    "    word_set = set(indexed_words)\n",
    "    dict_list = []\n",
    "    \n",
    "    for i in range(nr_rows):\n",
    "        for j in range(nr_cols):\n",
    "            \n",
    "            word = df.iat[i, j]\n",
    "            if word in word_set:\n",
    "                doc_id = df.index[i]\n",
    "                word_id = indexed_words.get_loc(word)\n",
    "                \n",
    "                item = {'MATERIAL_ID': doc_id,\n",
    "                       'OCCURENCE': 1, 'WORD_ID': word_id}\n",
    "                \n",
    "                dict_list.append(item)\n",
    "                \n",
    "    return pd.DataFrame(dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3623,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB  = 'DataSource/Trained Data/fabric_vocabulary.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3624,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = pd.read_csv(VOCAB, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3625,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MATERIAL_ID</th>\n",
       "      <th>OCCURENCE</th>\n",
       "      <th>WORD_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>577</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>578</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>579</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>581</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>582 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MATERIAL_ID  OCCURENCE  WORD_ID\n",
       "0              2          1       35\n",
       "1              2          1       14\n",
       "2              2          1       14\n",
       "3              2          1       14\n",
       "4              2          1       14\n",
       "..           ...        ...      ...\n",
       "577           11          1      244\n",
       "578           11          1      244\n",
       "579           11          1      258\n",
       "580           11          1      244\n",
       "581           11          1      244\n",
       "\n",
       "[582 rows x 3 columns]"
      ]
     },
     "execution_count": 3625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_predict_df = make_sparse_matrix(word_col_df, vocab)\n",
    "sparse_predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3626,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>OCCURENCE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MATERIAL_ID</th>\n",
       "      <th>WORD_ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"5\" valign=\"top\">2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"5\" valign=\"top\">11</td>\n",
       "      <td>244</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>291</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>651</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     OCCURENCE\n",
       "MATERIAL_ID WORD_ID           \n",
       "2           1                5\n",
       "            2                6\n",
       "            14               8\n",
       "            35               3\n",
       "            255              6\n",
       "...                        ...\n",
       "11          244              4\n",
       "            258              1\n",
       "            291              3\n",
       "            560              2\n",
       "            651              1\n",
       "\n",
       "[243 rows x 1 columns]"
      ]
     },
     "execution_count": 3626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_predict_df_grouped = sparse_predict_df.groupby(['MATERIAL_ID', 'WORD_ID']).sum()\n",
    "sparse_predict_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3627,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MATERIAL_ID</th>\n",
       "      <th>WORD_ID</th>\n",
       "      <th>OCCURENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>255</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238</td>\n",
       "      <td>11</td>\n",
       "      <td>244</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>239</td>\n",
       "      <td>11</td>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>11</td>\n",
       "      <td>291</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>241</td>\n",
       "      <td>11</td>\n",
       "      <td>560</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>242</td>\n",
       "      <td>11</td>\n",
       "      <td>651</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MATERIAL_ID  WORD_ID  OCCURENCE\n",
       "0              2        1          5\n",
       "1              2        2          6\n",
       "2              2       14          8\n",
       "3              2       35          3\n",
       "4              2      255          6\n",
       "..           ...      ...        ...\n",
       "238           11      244          4\n",
       "239           11      258          1\n",
       "240           11      291          3\n",
       "241           11      560          2\n",
       "242           11      651          1\n",
       "\n",
       "[243 rows x 3 columns]"
      ]
     },
     "execution_count": 3627,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_predict_df_grouped = sparse_predict_df_grouped.reset_index()\n",
    "sparse_predict_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3628,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2,   1,   5],\n",
       "       [  2,   2,   6],\n",
       "       [  2,  14,   8],\n",
       "       [  2,  35,   3],\n",
       "       [  2, 255,   6],\n",
       "       [  3, 111,   2],\n",
       "       [  3, 133,   1],\n",
       "       [  3, 171,   1],\n",
       "       [  3, 203,   1],\n",
       "       [  3, 240,   1],\n",
       "       [  3, 307,   1],\n",
       "       [  3, 309,   1],\n",
       "       [  3, 359,   1],\n",
       "       [  3, 400,   1],\n",
       "       [  3, 492,   1],\n",
       "       [  3, 699,   1],\n",
       "       [  3, 755,   1],\n",
       "       [  4,   1,   6],\n",
       "       [  4,   2,   4],\n",
       "       [  4,  11,   1],\n",
       "       [  4,  12,   2],\n",
       "       [  4,  14,   3],\n",
       "       [  4,  15,   1],\n",
       "       [  4,  21,   1],\n",
       "       [  4,  26,   3],\n",
       "       [  4,  34,   1],\n",
       "       [  4,  39,   2],\n",
       "       [  4,  43,   1],\n",
       "       [  4,  47,   1],\n",
       "       [  4,  48,   2],\n",
       "       [  4,  52,   1],\n",
       "       [  4,  59,   2],\n",
       "       [  4,  62,   2],\n",
       "       [  4,  74,   2],\n",
       "       [  4,  80,   2],\n",
       "       [  4, 100,   2],\n",
       "       [  4, 124,   3],\n",
       "       [  4, 131,   2],\n",
       "       [  4, 144,   1],\n",
       "       [  4, 147,   1],\n",
       "       [  4, 149,   1],\n",
       "       [  4, 173,   1],\n",
       "       [  4, 189,   1],\n",
       "       [  4, 191,   1],\n",
       "       [  4, 205,   2],\n",
       "       [  4, 237,   1],\n",
       "       [  4, 243,   1],\n",
       "       [  4, 257,   1],\n",
       "       [  4, 260,   1],\n",
       "       [  4, 322,   1],\n",
       "       [  4, 372,   1],\n",
       "       [  4, 632,   7],\n",
       "       [  5,   0,   1],\n",
       "       [  5,   1,   8],\n",
       "       [  5,   2,   5],\n",
       "       [  5,   9,   1],\n",
       "       [  5,  12,   1],\n",
       "       [  5,  15,   4],\n",
       "       [  5,  18,   3],\n",
       "       [  5,  20,   2],\n",
       "       [  5,  21,   1],\n",
       "       [  5,  24,   5],\n",
       "       [  5,  25,   3],\n",
       "       [  5,  29,   2],\n",
       "       [  5,  31,   2],\n",
       "       [  5,  34,   1],\n",
       "       [  5,  35,   2],\n",
       "       [  5,  36,   2],\n",
       "       [  5,  37,   4],\n",
       "       [  5,  39,   9],\n",
       "       [  5,  40,   2],\n",
       "       [  5,  43,   1],\n",
       "       [  5,  44,   3],\n",
       "       [  5,  47,   3],\n",
       "       [  5,  48,   2],\n",
       "       [  5,  49,   3],\n",
       "       [  5,  52,   1],\n",
       "       [  5,  55,   3],\n",
       "       [  5,  59,   4],\n",
       "       [  5,  62,   2],\n",
       "       [  5,  67,   1],\n",
       "       [  5,  68,   1],\n",
       "       [  5,  69,   2],\n",
       "       [  5,  70,   3],\n",
       "       [  5,  75,   1],\n",
       "       [  5,  79,   1],\n",
       "       [  5,  81,   5],\n",
       "       [  5,  84,   3],\n",
       "       [  5,  90,   1],\n",
       "       [  5,  95,   2],\n",
       "       [  5,  98,   1],\n",
       "       [  5, 100,   1],\n",
       "       [  5, 102,   2],\n",
       "       [  5, 105,   2],\n",
       "       [  5, 106,   1],\n",
       "       [  5, 113,   6],\n",
       "       [  5, 115,   1],\n",
       "       [  5, 117,   1],\n",
       "       [  5, 120,   1],\n",
       "       [  5, 122,   1],\n",
       "       [  5, 131,   2],\n",
       "       [  5, 133,   1],\n",
       "       [  5, 134,   1],\n",
       "       [  5, 135,   2],\n",
       "       [  5, 138,   1],\n",
       "       [  5, 142,   3],\n",
       "       [  5, 144,   1],\n",
       "       [  5, 145,   3],\n",
       "       [  5, 147,   1],\n",
       "       [  5, 151,   1],\n",
       "       [  5, 156,   2],\n",
       "       [  5, 162,   1],\n",
       "       [  5, 165,   2],\n",
       "       [  5, 168,   1],\n",
       "       [  5, 172,   1],\n",
       "       [  5, 180,   1],\n",
       "       [  5, 183,   1],\n",
       "       [  5, 185,   1],\n",
       "       [  5, 213,   1],\n",
       "       [  5, 216,   1],\n",
       "       [  5, 220,   1],\n",
       "       [  5, 222,   1],\n",
       "       [  5, 226,   2],\n",
       "       [  5, 229,   1],\n",
       "       [  5, 233,   2],\n",
       "       [  5, 234,   1],\n",
       "       [  5, 238,   2],\n",
       "       [  5, 244,   4],\n",
       "       [  5, 254,   1],\n",
       "       [  5, 255,   2],\n",
       "       [  5, 269,   1],\n",
       "       [  5, 296,   1],\n",
       "       [  5, 303,   1],\n",
       "       [  5, 311,   1],\n",
       "       [  5, 314,   1],\n",
       "       [  5, 345,   3],\n",
       "       [  5, 364,   1],\n",
       "       [  5, 372,   1],\n",
       "       [  5, 373,   1],\n",
       "       [  5, 376,   1],\n",
       "       [  5, 388,   1],\n",
       "       [  5, 389,   1],\n",
       "       [  5, 401,   1],\n",
       "       [  5, 402,   1],\n",
       "       [  5, 405,   1],\n",
       "       [  5, 412,   1],\n",
       "       [  5, 443,   1],\n",
       "       [  5, 445,   1],\n",
       "       [  5, 577,   1],\n",
       "       [  5, 592,   1],\n",
       "       [  5, 661,   1],\n",
       "       [  5, 703,   1],\n",
       "       [  5, 749,   1],\n",
       "       [  5, 756,   1],\n",
       "       [  5, 872,   1],\n",
       "       [  6,   0,   9],\n",
       "       [  6,   2,   1],\n",
       "       [  6,   3,   2],\n",
       "       [  6,   7,   1],\n",
       "       [  6,   8,   2],\n",
       "       [  6,   9,   3],\n",
       "       [  6,  10,   7],\n",
       "       [  6,  11,   1],\n",
       "       [  6,  12,   1],\n",
       "       [  6,  15,   1],\n",
       "       [  6,  19,   3],\n",
       "       [  6,  20,   4],\n",
       "       [  6,  22,   5],\n",
       "       [  6,  23,   6],\n",
       "       [  6,  27,   9],\n",
       "       [  6,  28,   4],\n",
       "       [  6,  29,   1],\n",
       "       [  6,  32,   1],\n",
       "       [  6,  34,   4],\n",
       "       [  6,  40,   9],\n",
       "       [  6,  43,   1],\n",
       "       [  6,  50,   2],\n",
       "       [  6,  53,   6],\n",
       "       [  6,  54,   2],\n",
       "       [  6,  55,   1],\n",
       "       [  6,  57,   6],\n",
       "       [  6,  58,   3],\n",
       "       [  6,  62,   1],\n",
       "       [  6,  63,   1],\n",
       "       [  6,  67,   5],\n",
       "       [  6,  71,   1],\n",
       "       [  6,  76,   1],\n",
       "       [  6,  77,   1],\n",
       "       [  6,  98,   1],\n",
       "       [  6, 103,   3],\n",
       "       [  6, 108,   2],\n",
       "       [  6, 118,   3],\n",
       "       [  6, 121,   2],\n",
       "       [  6, 122,   1],\n",
       "       [  6, 131,   1],\n",
       "       [  6, 140,   4],\n",
       "       [  6, 141,   1],\n",
       "       [  6, 144,   1],\n",
       "       [  6, 147,   1],\n",
       "       [  6, 149,   1],\n",
       "       [  6, 160,   1],\n",
       "       [  6, 176,   2],\n",
       "       [  6, 182,   1],\n",
       "       [  6, 190,   1],\n",
       "       [  6, 192,   1],\n",
       "       [  6, 197,   1],\n",
       "       [  6, 202,   2],\n",
       "       [  6, 207,   1],\n",
       "       [  6, 232,   3],\n",
       "       [  6, 244,   2],\n",
       "       [  6, 248,   1],\n",
       "       [  6, 250,   1],\n",
       "       [  6, 256,   1],\n",
       "       [  6, 316,   1],\n",
       "       [  6, 425,   1],\n",
       "       [  6, 481,   1],\n",
       "       [  6, 553,   1],\n",
       "       [  7,   1,   1],\n",
       "       [  7,  11,   1],\n",
       "       [  7,  14,   1],\n",
       "       [  8, 115,  27],\n",
       "       [  8, 244,   4],\n",
       "       [  8, 258,   1],\n",
       "       [  8, 291,   3],\n",
       "       [  8, 401,   1],\n",
       "       [  8, 560,   2],\n",
       "       [  9, 115,  21],\n",
       "       [  9, 244,   4],\n",
       "       [  9, 258,   1],\n",
       "       [  9, 291,   3],\n",
       "       [  9, 560,   2],\n",
       "       [  9, 651,   5],\n",
       "       [ 10, 115,  21],\n",
       "       [ 10, 244,   4],\n",
       "       [ 10, 258,   1],\n",
       "       [ 10, 291,   3],\n",
       "       [ 10, 560,   2],\n",
       "       [ 11, 115,  20],\n",
       "       [ 11, 244,   4],\n",
       "       [ 11, 258,   1],\n",
       "       [ 11, 291,   3],\n",
       "       [ 11, 560,   2],\n",
       "       [ 11, 651,   1]])"
      ]
     },
     "execution_count": 3628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_predict_data = sparse_predict_df_grouped.to_numpy()\n",
    "sparse_predict_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make_full_feature()\n",
    "### Full Matrix\n",
    "* Since we want to predict the data, so we create the Full Feature directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3629,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_full_feature(sparse_matrix, nr_words, doc_idx = 0, word_idx = 1, freq_idx = 2):\n",
    "    column_names = ['MATERIAL_ID'] + list(range(0, VOCAB_SIZE))\n",
    "    doc_id_names = np.unique(sparse_matrix[:,0])\n",
    "    full_matrix = pd.DataFrame(index = doc_id_names, columns = column_names)\n",
    "    full_matrix.fillna(value=0, inplace=True)\n",
    "    \n",
    "    for i in range(sparse_matrix.shape[0]):\n",
    "        doc_nr = sparse_matrix[i][doc_idx]\n",
    "        word_id = sparse_matrix[i][word_idx]\n",
    "        occurrence = sparse_matrix[i][freq_idx]\n",
    "        \n",
    "        full_matrix.at[doc_nr, 'MATERIAL_ID'] = doc_nr\n",
    "        full_matrix.at[doc_nr, word_id] = occurrence\n",
    "        \n",
    "    full_matrix.set_index('MATERIAL_ID', inplace = True)\n",
    "    return full_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3630,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>890</th>\n",
       "      <th>891</th>\n",
       "      <th>892</th>\n",
       "      <th>893</th>\n",
       "      <th>894</th>\n",
       "      <th>895</th>\n",
       "      <th>896</th>\n",
       "      <th>897</th>\n",
       "      <th>898</th>\n",
       "      <th>899</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MATERIAL_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 900 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0    1    2    3    4    5    6    7    8    9    ...  890  891  \\\n",
       "MATERIAL_ID                                                    ...             \n",
       "2              0    5    6    0    0    0    0    0    0    0  ...    0    0   \n",
       "3              0    0    0    0    0    0    0    0    0    0  ...    0    0   \n",
       "4              0    6    4    0    0    0    0    0    0    0  ...    0    0   \n",
       "5              1    8    5    0    0    0    0    0    0    1  ...    0    0   \n",
       "6              9    0    1    2    0    0    0    1    2    3  ...    0    0   \n",
       "7              0    1    0    0    0    0    0    0    0    0  ...    0    0   \n",
       "8              0    0    0    0    0    0    0    0    0    0  ...    0    0   \n",
       "9              0    0    0    0    0    0    0    0    0    0  ...    0    0   \n",
       "10             0    0    0    0    0    0    0    0    0    0  ...    0    0   \n",
       "11             0    0    0    0    0    0    0    0    0    0  ...    0    0   \n",
       "\n",
       "             892  893  894  895  896  897  898  899  \n",
       "MATERIAL_ID                                          \n",
       "2              0    0    0    0    0    0    0    0  \n",
       "3              0    0    0    0    0    0    0    0  \n",
       "4              0    0    0    0    0    0    0    0  \n",
       "5              0    0    0    0    0    0    0    0  \n",
       "6              0    0    0    0    0    0    0    0  \n",
       "7              0    0    0    0    0    0    0    0  \n",
       "8              0    0    0    0    0    0    0    0  \n",
       "9              0    0    0    0    0    0    0    0  \n",
       "10             0    0    0    0    0    0    0    0  \n",
       "11             0    0    0    0    0    0    0    0  \n",
       "\n",
       "[10 rows x 900 columns]"
      ]
     },
     "execution_count": 3630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_full_feature = make_full_feature(sparse_predict_data, vocab.shape[0])\n",
    "predict_full_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3631,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_1 = 'DataSource/Trained Data/fabric_prob_tokens_ctg_1_in_train_data'\n",
    "TRAIN_DATA_0 = 'DataSource/Trained Data/fabric_prob_tokens_ctg_0_in_train_data'\n",
    "TRAIN_DATA_ALL = 'DataSource/Trained Data/fabric_prob_tokens_all_in_train_data'\n",
    "PROB_1_TRAIN_DATA = 'DataSource/Trained Data/fabric_prob_ctg_1_in_train_data'\n",
    "train_data_1 = np.loadtxt(TRAIN_DATA_1)\n",
    "train_data_0 = np.loadtxt(TRAIN_DATA_0)\n",
    "train_data_all = np.loadtxt(TRAIN_DATA_ALL)\n",
    "prob_ctg_1 = pd.read_csv(PROB_1_TRAIN_DATA, index_col = 0)\n",
    "prob_ctg_1_train_data = prob_ctg_1.loc[0, 'prob_ctg_1_train_set']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3632,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MATERIAL_ID\n",
       "2     -40.730818\n",
       "3     -12.669810\n",
       "4    -124.054435\n",
       "5    -301.544279\n",
       "6     -74.619464\n",
       "7      -3.156802\n",
       "8     -53.979512\n",
       "9     -46.721459\n",
       "10    -44.810049\n",
       "11    -43.905252\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_log_ctg_1 = predict_full_feature.dot(np.log(train_data_1) - np.log(train_data_all)) + np.log(prob_ctg_1_train_data)\n",
    "joint_log_ctg_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3633,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MATERIAL_ID\n",
       "2     -1.582806\n",
       "3     -0.181254\n",
       "4      2.094748\n",
       "5    -46.424555\n",
       "6    -24.179751\n",
       "7     -0.851495\n",
       "8      4.203096\n",
       "9      4.556446\n",
       "10     3.416733\n",
       "11     3.541371\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_log_ctg_0 = predict_full_feature.dot(np.log(train_data_0)-np.log(train_data_all))+np.log(1 - prob_ctg_1_train_data)\n",
    "joint_log_ctg_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3634,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MATERIAL_ID\n",
       "2     False\n",
       "3     False\n",
       "4     False\n",
       "5     False\n",
       "6     False\n",
       "7     False\n",
       "8     False\n",
       "9     False\n",
       "10    False\n",
       "11    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 3634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_log = joint_log_ctg_1 > joint_log_ctg_0\n",
    "prediction_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core Funciton\n",
    "## Material_Classifor\n",
    "* Classifor the materials in the M-List, \n",
    "* Mateiral is in row direction in a M-List.\n",
    "* Return a list of index of row that classified as \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3635,
   "metadata": {},
   "outputs": [],
   "source": [
    "def material_classifor(bom, SUBJECT):\n",
    "    VOCAB  = 'DataSource/Trained Data/' + SUBJECT + '_vocabulary.csv'\n",
    "    TRAIN_DATA_1 = 'DataSource/Trained Data/' + SUBJECT + '_prob_tokens_ctg_1_in_train_data'\n",
    "    TRAIN_DATA_0 = 'DataSource/Trained Data/' + SUBJECT + '_prob_tokens_ctg_0_in_train_data'\n",
    "    TRAIN_DATA_ALL = 'DataSource/Trained Data/' + SUBJECT + '_prob_tokens_all_in_train_data'\n",
    "    PROB_1_TRAIN_DATA = 'DataSource/Trained Data/' + SUBJECT + '_prob_ctg_1_in_train_data'\n",
    "    '''\n",
    "    Param_1\n",
    "    <bom>\n",
    "    DataFrame, by reading M-List in csv format.\n",
    "    \n",
    "    Param_2\n",
    "    <SUBJECT>\n",
    "    It defines what to analyze, for example, of the SUBJECT == 'fabric', \n",
    "    then the func will use the trained_data set of fabric to analyze the documents.\n",
    "    \n",
    "    Local_var_1\n",
    "    <VOCAB>\n",
    "    The path of the vocabulary\n",
    "    Token list with WORD_ID\n",
    "    \n",
    "    Local_var_2\n",
    "    <TRAIN_DATA_1>\n",
    "    The trained data of catagory True\n",
    "    Probabilitie of each token in category True\n",
    "    \n",
    "    Local_var_3\n",
    "    <TRAIN_DATA_0>\n",
    "    The trained data of category False\n",
    "    Probabilitie of each token in category False\n",
    "    \n",
    "    Local_var_4\n",
    "    <TRAIN_DATA_ALL>\n",
    "    The trained data of category both.\n",
    "    Probabilitie of each token in all documents\n",
    "    \n",
    "    Local_var_5\n",
    "    <PROB_1_TRAIN_DATA>\n",
    "    The probability of documents in catagory True in all documents.\n",
    "    Number of documents in catagory True / number of all documents\n",
    "    '''\n",
    "    # read the vocabulary\n",
    "    vocab = pd.read_csv(VOCAB, index_col = 0)\n",
    "    # read the trained_datas\n",
    "    train_data_1 = np.loadtxt(TRAIN_DATA_1)\n",
    "    train_data_0 = np.loadtxt(TRAIN_DATA_0)\n",
    "    train_data_all = np.loadtxt(TRAIN_DATA_ALL)\n",
    "    prob_ctg_1 = pd.read_csv(PROB_1_TRAIN_DATA, index_col = 0)\n",
    "    prob_ctg_1_train_data = prob_ctg_1.loc[0, 'prob_ctg_1_train_set']\n",
    "    \n",
    "    \n",
    "    # Delete useless cols\n",
    "    col_deleted_bom = delete_col(bom)\n",
    "    \n",
    "    # Series\n",
    "    # Parse the bom, make each col getting together to be 1 col\n",
    "    new_bom = turn_series(col_deleted_bom)\n",
    "    \n",
    "    # nltk_convert\n",
    "    stemmed_bom = new_bom.apply(stemmered_nltk_convert)\n",
    "    \n",
    "    # Convert the stemmed series into df\n",
    "    # 1 token get 1 cell\n",
    "    word_col_df = pd.DataFrame.from_records(stemmed_bom.tolist())\n",
    "    \n",
    "    # Sparse Matrix\n",
    "    # Create a sparse Matrix for the data we want to predict\n",
    "    # The difference of this function in comparition with Classification Model for Train data, is this function don't need CATEGORY.\n",
    "    sparse_predict_df = make_sparse_matrix(word_col_df, vocab)\n",
    "    # Grouped by MATERIAL_ID\n",
    "    sparse_predict_df_grouped = sparse_predict_df.groupby(['MATERIAL_ID', 'WORD_ID']).sum()\n",
    "    # Reset it index\n",
    "    sparse_predict_df_grouped = sparse_predict_df_grouped.reset_index()\n",
    "    # Convert it into numpy array.\n",
    "    sparse_predict_data = sparse_predict_df_grouped.to_numpy()\n",
    "    \n",
    "    #Full Matrix\n",
    "    predict_full_feature = make_full_feature(sparse_predict_data, vocab.shape[0])\n",
    "    \n",
    "    #Joint probability in log format\n",
    "    joint_log_ctg_1 = predict_full_feature.dot(np.log(train_data_1) - np.log(train_data_all)) + np.log(prob_ctg_1_train_data)\n",
    "    joint_log_ctg_0 = predict_full_feature.dot(np.log(train_data_0)-np.log(train_data_all))+np.log(1 - prob_ctg_1_train_data)\n",
    "    # Prediction\n",
    "    prediction_log = joint_log_ctg_1 > joint_log_ctg_0\n",
    "    \n",
    "    # Get the index of the row that predicted as material in the bom\n",
    "    row_list = prediction_log[prediction_log == True].index\n",
    "    print(row_list)\n",
    "    #2020/03/11\n",
    "    # The difference with the func \"M-List_generator\" is that the func only return a list of index classified as True.\n",
    "    # Later I may optimize the func \"M-List_generator\" same as this func, so the two func can use same code as this func.\n",
    "    # Let the different part be done outside the func.\n",
    "#     # Get the material from the original bom by the index in row_list\n",
    "#     material_list = bom.loc[row_list,:]\n",
    "    \n",
    "    return row_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Funciton\n",
    "## Loop through materials designated as category.\n",
    "* Analyze a Categoried_M-List with several sets of train-data and vocabulary. \n",
    "* Each set of trainned-data and vocabulary represents 1 category of material, such as item, description, spec.\n",
    "* This func will feed the func \"material_classifor\" each set of trainned-data and vocabulary by order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3636,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 'DataSource/M-List/AB18MJ1_032_ BOM_032 BOM_material_list.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3637,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_out_col_category(M_list, Style_name, LIST = COL_LIST) :\n",
    "    '''\n",
    "    Param_1\n",
    "    <M_list>\n",
    "    M_list in CSV format\n",
    "    The func will turn it into a DataFrame while calculating.\n",
    "    \n",
    "    Param_2\n",
    "    The name of the file.\n",
    "\n",
    "    Param_3\n",
    "    An array in type List.\n",
    "    The content is the categories of material.\n",
    "    That decides which train_set data to be used.\n",
    "    '''\n",
    "    bom = pd.read_csv(M_list, index_col = None, encoding = 'ISO-8859-1')\n",
    "    #The code below may not using in the col classify.\n",
    "#     bom.insert(1, 'CATEGORY', 'other', True)\n",
    "\n",
    "    # Add a new row\n",
    "    new_bom = bom.append(pd.Series(name = 'TITLE'))\n",
    "    \n",
    "    new_bom.loc['TITLE', 'MATERIAL_ID'] = 'MATERIAL_ID'\n",
    "    new_bom.loc['TITLE', 'CATEGORY'] = 'CATEGORY'\n",
    "\n",
    "\n",
    "    for cate in LIST:\n",
    "        ROW_LIST = material_classifor(bom, cate)\n",
    "        print(ROW_LIST.values)\n",
    "        \n",
    "        # Loop through the ROW_LIST, change the cell in the row \"TITLE\" and in the col that with integer postion as the Int in ROW_LIST. \n",
    "        # notice, the method iat can only handle one col for one time, so here must use For Loop to get the job done.\n",
    "        # Since the new row \"TITLE\" is on the buttom of the df, the new_bom, so the integer position of the row is '-1'\n",
    "        for index in ROW_LIST:\n",
    "            new_bom.iat[-1, index] = cate\n",
    "            \n",
    "    #Set the row \"TITLE\" as the columns of the new_bom\n",
    "    new_bom.columns = new_bom.iloc[-1]\n",
    "    #Delete the last row, that must and should be the row \"TITLE\"\n",
    "    new_bom.drop(new_bom.index[-1], inplace = True)\n",
    "    \n",
    "    new_bom.to_csv('result/' + Style_name + '_COL_classified_M-List.csv')\n",
    "    return new_bom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3650,
   "metadata": {},
   "outputs": [],
   "source": [
    "bom = pd.read_csv(DATA, index_col = None, encoding = 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3645,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>a1</td>\n",
       "      <td>b1</td>\n",
       "      <td>c1</td>\n",
       "      <td>c1</td>\n",
       "      <td>c1</td>\n",
       "      <td>c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>a2</td>\n",
       "      <td>b2</td>\n",
       "      <td>c2</td>\n",
       "      <td>c2</td>\n",
       "      <td>c2</td>\n",
       "      <td>c2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>a3</td>\n",
       "      <td>b3</td>\n",
       "      <td>c3</td>\n",
       "      <td>c3</td>\n",
       "      <td>c3</td>\n",
       "      <td>c3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    a   b   c   d   e   f\n",
       "0  a1  b1  c1  c1  c1  c1\n",
       "1  a2  b2  c2  c2  c2  c2\n",
       "2  a3  b3  c3  c3  c3  c3"
      ]
     },
     "execution_count": 3645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3640,
   "metadata": {},
   "outputs": [],
   "source": [
    "bom = pd.DataFrame({\n",
    "    'a':['a1', 'a2', 'a3'],\n",
    "    'b':['b1', 'b2', 'b3'],\n",
    "    'c':['c1', 'c2', 'c3'],\n",
    "    'd':['c1', 'c2', 'c3'],\n",
    "    'e':['c1', 'c2', 'c3'],\n",
    "    'f':['c1', 'c2', 'c3'],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3641,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>a1</td>\n",
       "      <td>b1</td>\n",
       "      <td>c1</td>\n",
       "      <td>c1</td>\n",
       "      <td>c1</td>\n",
       "      <td>c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>a2</td>\n",
       "      <td>b2</td>\n",
       "      <td>c2</td>\n",
       "      <td>c2</td>\n",
       "      <td>c2</td>\n",
       "      <td>c2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>a3</td>\n",
       "      <td>b3</td>\n",
       "      <td>c3</td>\n",
       "      <td>c3</td>\n",
       "      <td>c3</td>\n",
       "      <td>c3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    a   b   c   d   e   f\n",
       "0  a1  b1  c1  c1  c1  c1\n",
       "1  a2  b2  c2  c2  c2  c2\n",
       "2  a3  b3  c3  c3  c3  c3"
      ]
     },
     "execution_count": 3641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walk through a dir \n",
    "* Check each xlsx in a dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3642,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_list_cate_classify_convertor(FROM_DIR, TO_DIR):\n",
    "    converted_csv_num = 0\n",
    "    for root, dirnames, filenames in walk(FROM_DIR):\n",
    "        # walk through each xlsx file\n",
    "        for file_name in filenames:\n",
    "             # get the path of the file\n",
    "            # Appoint the method only work with .xlsx file.\n",
    "            if file_name.endswith('.csv') :\n",
    "                converted_csv_num = converted_csv_num + 1\n",
    "                filepath = join(root, file_name)\n",
    "                # Custom function\n",
    "                fill_out_col_category(filepath, file_name[0:-18])\n",
    "    print('Converted ', converted_csv_num, ' files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3643,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([48, 49, 50, 51], dtype='int64', name='MATERIAL_ID')\n",
      "[48 49 50 51]\n",
      "Int64Index([], dtype='int64', name='MATERIAL_ID')\n",
      "[]\n",
      "Int64Index([], dtype='int64', name='MATERIAL_ID')\n",
      "[]\n",
      "Int64Index([1, 2, 3, 4, 5, 6], dtype='int64', name='MATERIAL_ID')\n",
      "[1 2 3 4 5 6]\n",
      "Int64Index([], dtype='int64', name='MATERIAL_ID')\n",
      "[]\n",
      "Int64Index([], dtype='int64', name='MATERIAL_ID')\n",
      "[]\n",
      "Int64Index([], dtype='int64', name='MATERIAL_ID')\n",
      "[]\n",
      "Int64Index([], dtype='int64', name='MATERIAL_ID')\n",
      "[]\n",
      "Int64Index([5], dtype='int64', name='MATERIAL_ID')\n",
      "[5]\n",
      "Int64Index([], dtype='int64', name='MATERIAL_ID')\n",
      "[]\n",
      "Int64Index([33, 34, 35, 36, 37, 39], dtype='int64', name='MATERIAL_ID')\n",
      "[33 34 35 36 37 39]\n",
      "Int64Index([1, 10, 13], dtype='int64', name='MATERIAL_ID')\n",
      "[ 1 10 13]\n",
      "Int64Index([14, 15, 40, 41, 43, 44], dtype='int64', name='MATERIAL_ID')\n",
      "[14 15 40 41 43 44]\n",
      "Int64Index([17, 18, 19, 20, 45], dtype='int64', name='MATERIAL_ID')\n",
      "[17 18 19 20 45]\n",
      "Int64Index([1, 2, 3, 4, 5, 6, 7, 8, 9, 13], dtype='int64', name='MATERIAL_ID')\n",
      "[ 1  2  3  4  5  6  7  8  9 13]\n",
      "Int64Index([], dtype='int64', name='MATERIAL_ID')\n",
      "[]\n",
      "Int64Index([8, 9, 10, 11], dtype='int64', name='MATERIAL_ID')\n",
      "[ 8  9 10 11]\n",
      "Int64Index([9], dtype='int64', name='MATERIAL_ID')\n",
      "[9]\n",
      "Int64Index([], dtype='int64', name='MATERIAL_ID')\n",
      "[]\n",
      "Int64Index([], dtype='int64', name='MATERIAL_ID')\n",
      "[]\n",
      "Converted  4  files\n",
      "CPU times: user 7.89 s, sys: 124 ms, total: 8.01 s\n",
      "Wall time: 5.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "m_list_cate_classify_convertor(FROM_DIR, TO_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
