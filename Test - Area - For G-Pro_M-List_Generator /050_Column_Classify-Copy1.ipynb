{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test for the code copied from 020 and 040 to Project the \"G-Pro_M-List generator API\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# NLTK\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "# Switch area\n",
    "SUBJECT = 'material_garment'\n",
    "VOCAB_SIZE = 900\n",
    "COL_LIST =['item', 'description', 'color_way', 'position', 'spec', 'fabric']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete_col()\n",
    "### Delete the none columns in a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_col(m_list):\n",
    "    for col in m_list:\n",
    "        if m_list[col].count() == 0:\n",
    "            m_list = m_list.drop(col, axis = 1)\n",
    "    return m_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stemmered_nltk_convert()\n",
    "###  Nltk stemmered Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmered_nltk_convert(col_of_df):\n",
    "    '''\n",
    "    Parameter of this function is a column of a dataFrame.\n",
    "\n",
    "    '''\n",
    "    # difine Stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # Difine Stemmer\n",
    "    stemmer = SnowballStemmer('english')\n",
    "\n",
    "    # converts to lower case and splits up the words\n",
    "    words = word_tokenize(col_of_df)\n",
    "    filtered_words = []\n",
    "\n",
    "    for word in words:\n",
    "        # Removes the stop words and punctuation\n",
    "        # if word is not in the stop_words list and is not a alpha.\n",
    "        if word not in stop_words and word.isalpha():\n",
    "            filtered_words.append(stemmer.stem(word))\n",
    "\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## turn_series()\n",
    "### Walk through bom\n",
    "### Copyed from 040_21 - Column-Classify\n",
    "* Parse a xlsm of bom, turn the columns into cells, all the cells will form a col.\n",
    "* Put the cell to the classify function\n",
    "* Return the index of column that is True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_series(bom):\n",
    "    '''\n",
    "    bom: DataFrame, \n",
    "    \n",
    "    '''\n",
    "    database = []\n",
    "    \n",
    "    for col in bom:\n",
    "        col_str = str()\n",
    "        for row in bom.index:\n",
    "            col_str = col_str + ', ' + str(bom.at[row, col])\n",
    "        database.append(col_str)\n",
    "    \n",
    "    col = pd.Series(database)\n",
    "#     index_list = classify_series(col)\n",
    "    \n",
    "    return col#### Below is the original function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make_sparse_matrix()\n",
    "### Sparse Matrix Function\n",
    "* Create a sparse Matrix for the data we want to predict\n",
    "* The difference of this function in comparition with Classification Model for Train data, is this function don't need CATEGORY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sparse_matrix(df, vocabulary):\n",
    "    \"\"\"\n",
    "    Param1:\n",
    "    The data we want to sparse, which must be in format of DataFrame.\n",
    "    Param2:\n",
    "    The vocabulary, it is generated when we training datas.\n",
    "\n",
    "    Returns a sparse matrix as dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    indexed_words = pd.Index(vocabulary.VOCAB_WORD)\n",
    "    nr_rows = df.shape[0]\n",
    "    nr_cols = df.shape[1]\n",
    "    word_set = set(indexed_words)\n",
    "    dict_list = []\n",
    "\n",
    "    for i in range(nr_rows):\n",
    "        for j in range(nr_cols):\n",
    "\n",
    "            word = df.iat[i, j]\n",
    "            if word in word_set:\n",
    "                doc_id = df.index[i]\n",
    "                word_id = indexed_words.get_loc(word)\n",
    "\n",
    "                item = {'MATERIAL_ID': doc_id,\n",
    "                        'OCCURENCE': 1, 'WORD_ID': word_id}\n",
    "\n",
    "                dict_list.append(item)\n",
    "\n",
    "    return pd.DataFrame(dict_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make_full_feature()\n",
    "## Full Matrix\n",
    "* Since we want to predict the data, so we create the Full Feature directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_full_feature(sparse_matrix, nr_words, doc_idx=0, word_idx=1, freq_idx=2):\n",
    "    column_names = ['MATERIAL_ID'] + list(range(0, VOCAB_SIZE))\n",
    "    doc_id_names = np.unique(sparse_matrix[:, 0])\n",
    "    full_matrix = pd.DataFrame(index=doc_id_names, columns=column_names)\n",
    "    full_matrix.fillna(value=0, inplace=True)\n",
    "\n",
    "    for i in range(sparse_matrix.shape[0]):\n",
    "        doc_nr = sparse_matrix[i][doc_idx]\n",
    "        word_id = sparse_matrix[i][word_idx]\n",
    "        occurrence = sparse_matrix[i][freq_idx]\n",
    "\n",
    "        full_matrix.at[doc_nr, 'MATERIAL_ID'] = doc_nr\n",
    "        full_matrix.at[doc_nr, word_id] = occurrence\n",
    "\n",
    "    full_matrix.set_index('MATERIAL_ID', inplace=True)\n",
    "    return full_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Funciton -----------------------------------------------------\n",
    "* The func in this area is not root func. The func here uses some other func as part of it.\n",
    "\n",
    "# M-List_generator\n",
    "* From 040_21 - Column_Classify\n",
    "* Pick up material rows from a bom of xlsx and form it a dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def material_list_generator(JSONbom,\n",
    "                            VOCAB='DataSource/Trained Data/' + SUBJECT + '_vocabulary.csv',\n",
    "                            TRAIN_DATA_1='DataSource/Trained Data/' +\n",
    "                            SUBJECT + '_prob_tokens_ctg_1_in_train_data',\n",
    "                            TRAIN_DATA_0='DataSource/Trained Data/' +\n",
    "                            SUBJECT + '_prob_tokens_ctg_0_in_train_data',\n",
    "                            TRAIN_DATA_ALL='DataSource/Trained Data/' +\n",
    "                            SUBJECT + '_prob_tokens_all_in_train_data',\n",
    "                            PROB_1_TRAIN_DATA='DataSource/Trained Data/' + SUBJECT + '_prob_ctg_1_in_train_data'):\n",
    "    '''\n",
    "    Param_1\n",
    "    Bom in JSON format, JSON is an array, the rows is an array under the JSON array.\n",
    "\n",
    "    Param_2\n",
    "    The path of the vocabulary\n",
    "    Token list with WORD_ID\n",
    "\n",
    "    Param_3\n",
    "    The trained data of catagory True\n",
    "    Probabilitie of each token in category True\n",
    "\n",
    "    Param_4\n",
    "    The trained data of category False\n",
    "    Probabilitie of each token in category False\n",
    "\n",
    "    Param_5\n",
    "    The trained data of category both.\n",
    "    Probabilitie of each token in all documents\n",
    "\n",
    "    Param_6\n",
    "    The percentage of documents in catagory True in all documents.\n",
    "    Number of documents in catagory True / number of all documents\n",
    "    '''\n",
    "    # read the vocabulary\n",
    "    vocab = pd.read_csv(VOCAB, index_col=0)\n",
    "    # read the trained_datas\n",
    "    train_data_1 = np.loadtxt(TRAIN_DATA_1)\n",
    "    train_data_0 = np.loadtxt(TRAIN_DATA_0)\n",
    "    train_data_all = np.loadtxt(TRAIN_DATA_ALL)\n",
    "    prob_ctg_1 = pd.read_csv(PROB_1_TRAIN_DATA, index_col=0)\n",
    "    prob_ctg_1_train_data = prob_ctg_1.loc[0, 'prob_ctg_1_train_set']\n",
    "\n",
    "    # Read JSON\n",
    "    bom = pd.read_json(JSONbom)\n",
    "\n",
    "    # Delete useless cols\n",
    "    col_deleted_bom = delete_col(bom)\n",
    "\n",
    "    # Series\n",
    "    # Parse the bom, make each col getting together to be 1 col\n",
    "    new_bom = turn_series(col_deleted_bom)\n",
    "\n",
    "    # nltk_convert\n",
    "    stemmed_bom = new_bom.apply(stemmered_nltk_convert)\n",
    "\n",
    "    # Convert the stemmed series into df\n",
    "    # 1 token get 1 cell\n",
    "    word_col_df = pd.DataFrame.from_records(stemmed_bom.tolist())\n",
    "\n",
    "    # Sparse Matrix\n",
    "    # Create a sparse Matrix for the data we want to predict\n",
    "    # The difference of this function in comparition with Classification Model for Train data, is this function don't need CATEGORY.\n",
    "    sparse_predict_df = make_sparse_matrix(word_col_df, vocab)\n",
    "    # Grouped by MATERIAL_ID\n",
    "    sparse_predict_df_grouped = sparse_predict_df.groupby(\n",
    "        ['MATERIAL_ID', 'WORD_ID']).sum()\n",
    "    # Reset it index\n",
    "    sparse_predict_df_grouped = sparse_predict_df_grouped.reset_index()\n",
    "    # Convert it into numpy array.\n",
    "    sparse_predict_data = sparse_predict_df_grouped.to_numpy()\n",
    "\n",
    "    # Full Matrix\n",
    "    predict_full_feature = make_full_feature(\n",
    "        sparse_predict_data, vocab.shape[0])\n",
    "\n",
    "    # Joint probability in log format\n",
    "    joint_log_ctg_1 = predict_full_feature.dot(\n",
    "        np.log(train_data_1) - np.log(train_data_all)) + np.log(prob_ctg_1_train_data)\n",
    "    joint_log_ctg_0 = predict_full_feature.dot(\n",
    "        np.log(train_data_0)-np.log(train_data_all))+np.log(1 - prob_ctg_1_train_data)\n",
    "    # Prediction\n",
    "    prediction_log = joint_log_ctg_1 > joint_log_ctg_0\n",
    "\n",
    "    # Get the index of the row that predicted as material in the bom\n",
    "    row_list = prediction_log[prediction_log == True].index\n",
    "\n",
    "    # Get the material from the original bom by the index in row_list\n",
    "    material_list = bom.loc[row_list, :]\n",
    "    material_list.to_csv('result/classified_M-List.csv')\n",
    "\n",
    "    return material_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Material_Classifor Part-1\n",
    "## From 040_21 - Column_Classify\n",
    "* Classifor the materials in the M-List,\n",
    "* Mateiral is in row direction in a M-List.\n",
    "* Return a list of index of row that classified as \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def material_classifor(bom, SUBJECT):\n",
    "    VOCAB  = 'DataSource/Trained Data/' + SUBJECT + '_vocabulary.csv'\n",
    "    TRAIN_DATA_1 = 'DataSource/Trained Data/' + SUBJECT + '_prob_tokens_ctg_1_in_train_data'\n",
    "    TRAIN_DATA_0 = 'DataSource/Trained Data/' + SUBJECT + '_prob_tokens_ctg_0_in_train_data'\n",
    "    TRAIN_DATA_ALL = 'DataSource/Trained Data/' + SUBJECT + '_prob_tokens_all_in_train_data'\n",
    "    PROB_1_TRAIN_DATA = 'DataSource/Trained Data/' + SUBJECT + '_prob_ctg_1_in_train_data'\n",
    "    '''\n",
    "    Param_1\n",
    "    bom: String,\n",
    "    The path of a DataFrame, \n",
    "    by reading M-List in csv format.\n",
    "    \n",
    "    Param_2\n",
    "    SUBJECT: String, \n",
    "    It defines what to analyze, for example, of the SUBJECT == 'fabric', \n",
    "    then the func will use the trained_data set of fabric to analyze the documents.\n",
    "    \n",
    "    Local_var_1\n",
    "    VOCAB: String, \n",
    "    The path of the vocabulary\n",
    "    Token list with WORD_ID\n",
    "    \n",
    "    Local_var_2\n",
    "    TRAIN_DATA_1: String, \n",
    "    The path of trained data\n",
    "    The trained data of catagory True\n",
    "    Probabilitie of each token in category True\n",
    "    \n",
    "    Local_var_3\n",
    "    TRAIN_DATA_0: String, \n",
    "    The path of trained data\n",
    "    The trained data of category False\n",
    "    Probabilitie of each token in category False\n",
    "    \n",
    "    Local_var_4\n",
    "    TRAIN_DATA_ALL: String\n",
    "    The path of trained data\n",
    "    The trained data of category both.\n",
    "    Probabilitie of each token in all documents\n",
    "    \n",
    "    Local_var_5\n",
    "    PROB_1_TRAIN_DATA: String\n",
    "    The path of trained data\n",
    "    The percentage of documents in catagory True in all documents.\n",
    "    Number of documents in catagory True / number of all documents\n",
    "    '''\n",
    "    # read the vocabulary\n",
    "    vocab = pd.read_csv(VOCAB, index_col = 0)\n",
    "    # read the trained_datas\n",
    "    train_data_1 = np.loadtxt(TRAIN_DATA_1)\n",
    "    train_data_0 = np.loadtxt(TRAIN_DATA_0)\n",
    "    train_data_all = np.loadtxt(TRAIN_DATA_ALL)\n",
    "    prob_ctg_1 = pd.read_csv(PROB_1_TRAIN_DATA, index_col = 0)\n",
    "    prob_ctg_1_train_data = prob_ctg_1.loc[0, 'prob_ctg_1_train_set']\n",
    "    \n",
    "    \n",
    "    # Delete useless cols\n",
    "    col_deleted_bom = delete_col(bom)\n",
    "    \n",
    "    # Series\n",
    "    # Parse the bom, make each col getting together to be 1 col\n",
    "    new_bom = turn_series(col_deleted_bom)\n",
    "    \n",
    "    # nltk_convert\n",
    "    stemmed_bom = new_bom.apply(stemmered_nltk_convert)\n",
    "    \n",
    "    # Convert the stemmed series into df\n",
    "    # 1 token get 1 cell\n",
    "    word_col_df = pd.DataFrame.from_records(stemmed_bom.tolist())\n",
    "    \n",
    "    # Sparse Matrix\n",
    "    # Create a sparse Matrix for the data we want to predict\n",
    "    # The difference of this function in comparition with Classification Model for Train data, is this function don't need CATEGORY.\n",
    "    sparse_predict_df = make_sparse_matrix(word_col_df, vocab)\n",
    "    # Grouped by MATERIAL_ID\n",
    "    sparse_predict_df_grouped = sparse_predict_df.groupby(['MATERIAL_ID', 'WORD_ID']).sum()\n",
    "    # Reset it index\n",
    "    sparse_predict_df_grouped = sparse_predict_df_grouped.reset_index()\n",
    "    # Convert it into numpy array.\n",
    "    sparse_predict_data = sparse_predict_df_grouped.to_numpy()\n",
    "    \n",
    "    #Full Matrix\n",
    "    predict_full_feature = make_full_feature(sparse_predict_data, vocab.shape[0])\n",
    "    \n",
    "    #Joint probability in log format\n",
    "    joint_log_ctg_1 = predict_full_feature.dot(np.log(train_data_1) - np.log(train_data_all)) + np.log(prob_ctg_1_train_data)\n",
    "    joint_log_ctg_0 = predict_full_feature.dot(np.log(train_data_0)-np.log(train_data_all))+np.log(1 - prob_ctg_1_train_data)\n",
    "    # Prediction\n",
    "    prediction_log = joint_log_ctg_1 > joint_log_ctg_0\n",
    "    \n",
    "    # Get the index of the row that predicted as material in the bom\n",
    "    row_list = prediction_log[prediction_log == True].index\n",
    "    print(row_list)\n",
    "    #2020/03/11\n",
    "    # The difference with the func \"M-List_generator\" is that the func only return a list of index classified as True.\n",
    "    # Later I may optimize the func \"M-List_generator\" same as this func, so the two func can use same code as this func.\n",
    "    # Let the different part be done outside the func.\n",
    "#     # Get the material from the original bom by the index in row_list\n",
    "#     material_list = bom.loc[row_list,:]\n",
    "    \n",
    "    return row_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Material classify Part-2\n",
    "## Loop through materials designated as category.\n",
    "* Analyze a Categoried_M-List with several sets of train-data and vocabulary.\n",
    "* Each set of trainned-data and vocabulary represents 1 category of material, such as item, description, spec.\n",
    "* This func will feed the func \"material_classifor\" each set of trainned-data and vocabulary by order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_out_col_category(M_list, Style_name, LIST = COL_LIST) :\n",
    "    '''\n",
    "    # Arguments\n",
    "    M_list: String,  \n",
    "    the path of M_list in CSV format. M_list in CSV format. The func will turn it into a DataFrame while calculating.\n",
    "            \n",
    "    Style_name: String,  \n",
    "    the name of the file.\n",
    "            \n",
    "    LIST: List,  \n",
    "    An array in type List. The content is the categories of material. That decides which train_set data to be used.\n",
    "    \n",
    "    # Returns\n",
    "        A M_List in csv fomat, filled out the name of columns, such as 'item', 'description', 'spec', etc.\n",
    "    '''\n",
    "    #bom = pd.read_csv(M_list, index_col = None, encoding = 'ISO-8859-1')\n",
    "    bom = pd.read_json(M_list, encoding = 'ISO-8859-1')\n",
    "    #The code below may not using in the col classify.\n",
    "    #bom.insert(1, 'CATEGORY', 'other', True)\n",
    "\n",
    "    # Add a new row\n",
    "    new_bom = bom.append(pd.Series(name = 'TITLE'))\n",
    "    \n",
    "    new_bom.loc['TITLE', 'MATERIAL_ID'] = 'MATERIAL_ID'\n",
    "    new_bom.loc['TITLE', 'CATEGORY'] = 'CATEGORY'\n",
    "\n",
    "\n",
    "    for cate in LIST:\n",
    "        ROW_LIST = material_classifor(bom, cate)\n",
    "        print(ROW_LIST.values)\n",
    "        \n",
    "        # Loop through the ROW_LIST, change the cell in the row \"TITLE\" and in the col that with integer postion as the Int in ROW_LIST. \n",
    "        # notice, the method iat can only handle one col for one time, so here must use For Loop to get the job done.\n",
    "        # Since the new row \"TITLE\" is on the buttom of the df, the new_bom, so the integer position of the row is '-1'\n",
    "        for index in ROW_LIST:\n",
    "            new_bom.iat[-1, index] = cate\n",
    "            \n",
    "    #Set the row \"TITLE\" as the columns of the new_bom\n",
    "    new_bom.columns = new_bom.iloc[-1]\n",
    "    #Delete the last row, that must and should be the row \"TITLE\"\n",
    "    new_bom.drop(new_bom.index[-1], inplace = True)\n",
    "    \n",
    "    new_bom.to_csv('result/Col_Classify_M-List/' + Style_name + '_COL_classified_M-List.csv')\n",
    "    return new_bom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(JSON_BOM)\n",
    "JSON_BOM ='DataSource/JSON_original_bom/BOM.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MATERIAL_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Designer:   JG</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Season: Winter 2017/18</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Insulation:</td>\n",
       "      <td>60gm Insulation at body sleeve,hood</td>\n",
       "      <td>None</td>\n",
       "      <td>Collection: Freedom</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0     1            2                                    3  \\\n",
       "MATERIAL_ID                                                                 \n",
       "1            None  None         None                                 None   \n",
       "2            None  None         None                                 None   \n",
       "3            None  None  Insulation:  60gm Insulation at body sleeve,hood   \n",
       "\n",
       "                4                       5     6     7     8     9  \n",
       "MATERIAL_ID                                                        \n",
       "1            None          Designer:   JG  None  None  None  None  \n",
       "2            None  Season: Winter 2017/18  None  None  None  None  \n",
       "3            None     Collection: Freedom  None  None  None  None  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "material_list_generator(JSON_BOM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevehsu/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:86: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/stevehsu/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:87: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([], dtype='int64', name='MATERIAL_ID')\n",
      "[]\n",
      "Int64Index([], dtype='int64', name='MATERIAL_ID')\n",
      "[]\n",
      "Int64Index([5, 6, 7, 8], dtype='int64', name='MATERIAL_ID')\n",
      "[5 6 7 8]\n",
      "Int64Index([3], dtype='int64', name='MATERIAL_ID')\n",
      "[3]\n",
      "Int64Index([], dtype='int64', name='MATERIAL_ID')\n",
      "[]\n",
      "Int64Index([], dtype='int64', name='MATERIAL_ID')\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>TITLE</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>position</th>\n",
       "      <th>NaN</th>\n",
       "      <th>color_way</th>\n",
       "      <th>color_way</th>\n",
       "      <th>color_way</th>\n",
       "      <th>color_way</th>\n",
       "      <th>NaN</th>\n",
       "      <th>MATERIAL_ID</th>\n",
       "      <th>CATEGORY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>AIRBLASTER</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Style Number: AB18MJ2_081</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Designer:   JG</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Season: Winter 2017/18</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Insulation:</td>\n",
       "      <td>60gm Insulation at body sleeve,hood</td>\n",
       "      <td>None</td>\n",
       "      <td>Collection: Freedom</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Style Name:</td>\n",
       "      <td>None</td>\n",
       "      <td>Seams:</td>\n",
       "      <td>Critically Taped</td>\n",
       "      <td>None</td>\n",
       "      <td>Vendor: Soluna</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>ZIPPER DIRECTION:</td>\n",
       "      <td>CF has right hand slider, pocket zippers close...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>4</td>\n",
       "      <td>BARTACK:</td>\n",
       "      <td>At stress points</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>5</td>\n",
       "      <td>HEAT CUT:</td>\n",
       "      <td>Elastic, webbing, taffeta</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>6</td>\n",
       "      <td>GROMMETS/SNAPS:</td>\n",
       "      <td>Should have pellon backing</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>7</td>\n",
       "      <td>THREAD COLOR:</td>\n",
       "      <td>Matches fabric color, unless noted above</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "TITLE          NaN                NaN  \\\n",
       "0       AIRBLASTER               None   \n",
       "1             None               None   \n",
       "2             None               None   \n",
       "3             None               None   \n",
       "4      Style Name:               None   \n",
       "..             ...                ...   \n",
       "56               3  ZIPPER DIRECTION:   \n",
       "57               4           BARTACK:   \n",
       "58               5          HEAT CUT:   \n",
       "59               6    GROMMETS/SNAPS:   \n",
       "60               7      THREAD COLOR:   \n",
       "\n",
       "TITLE                                                NaN  \\\n",
       "0                                                   None   \n",
       "1                                                   None   \n",
       "2                                                   None   \n",
       "3                                            Insulation:   \n",
       "4                                                 Seams:   \n",
       "..                                                   ...   \n",
       "56     CF has right hand slider, pocket zippers close...   \n",
       "57                                      At stress points   \n",
       "58                             Elastic, webbing, taffeta   \n",
       "59                            Should have pellon backing   \n",
       "60              Matches fabric color, unless noted above   \n",
       "\n",
       "TITLE                             position   NaN                  color_way  \\\n",
       "0                                     None  None  Style Number: AB18MJ2_081   \n",
       "1                                     None  None             Designer:   JG   \n",
       "2                                     None  None     Season: Winter 2017/18   \n",
       "3      60gm Insulation at body sleeve,hood  None        Collection: Freedom   \n",
       "4                         Critically Taped  None             Vendor: Soluna   \n",
       "..                                     ...   ...                        ...   \n",
       "56                                    None  None                       None   \n",
       "57                                    None  None                       None   \n",
       "58                                    None  None                       None   \n",
       "59                                    None  None                       None   \n",
       "60                                    None  None                       None   \n",
       "\n",
       "TITLE color_way color_way color_way   NaN MATERIAL_ID CATEGORY  \n",
       "0          None      None      None  None         NaN      NaN  \n",
       "1          None      None      None  None         NaN      NaN  \n",
       "2          None      None      None  None         NaN      NaN  \n",
       "3          None      None      None  None         NaN      NaN  \n",
       "4          None      None      None  None         NaN      NaN  \n",
       "..          ...       ...       ...   ...         ...      ...  \n",
       "56         None      None      None  None         NaN      NaN  \n",
       "57         None      None      None  None         NaN      NaN  \n",
       "58         None      None      None  None         NaN      NaN  \n",
       "59         None      None      None  None         NaN      NaN  \n",
       "60         None      None      None  None         NaN      NaN  \n",
       "\n",
       "[61 rows x 12 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_out_col_category(JSON_BOM, 'Test_JSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
